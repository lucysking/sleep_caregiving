#qnorm(0.975)
# return the values as a vector
return(c(lower_cutoff,upper_cutoff))
}
# run the function on the score variable contained in the
# normalSample data frame
normalSampleCI <- myConfInt(normalSample$score)
mySample
nRuns <- 1000
results <- replicate(nRuns, sampleAndComputeCI)
sampleAndComputeCI <- function(sampleSize=100){
mySample <- normalPopulation %>%
sample_n(size = sampleSize)
myCI <- myConfInt(mySample)
return(myCI)
}
results <- replicate(nRuns, sampleAndComputeCI)
sampleAndComputeCI <- function(sampleSize=100){
mySample <- normalPopulation %>%
sample_n(size = sampleSize)
myCI <- myConfInt(mySample$score)
return(myCI)
}
nRuns <- 1000
results <- replicate(nRuns, sampleAndComputeCI)
# CODE PROVIDED
# the t() function transposes the results so that each row is one replication
resultsDf <- data.frame(t(results))
names(resultsDf) <- c('lower_cutoff','upper_cutoff')
resultsDf
library(tidyverse)
source('https://raw.githubusercontent.com/psych10/psych10/master/problem_sets/Week5/week5_tests.R')
### FILL IN THE BLANK
### insert your sunet id in the blank - e.g. "russpold"
sunetID <- "______"
### PROVIDED CODE
cat(paste('please confirm that your sunet ID is:',sunetID))
#set.seed(12345)  # DO NOT CHANGE THIS
normalPopulation <- tibble(score = rnorm(1000, mean = 100, sd = 10))
popSummary <- normalPopulation %>%
summarize(scoreMean = mean(score),
scoreSD = sd(score))
popSummary
sampleSize <- 100
normalSample <- normalPopulation %>%
sample_n(sampleSize)
# function should take two arguments:
# d: the data to be processed
# percentile: the percentile for the confidence interval, default value of 95
# it should return a vector containing two numbers: the lower and upper bounds of the confidence interval
myConfInt <- function(d,percentile = 95){
# compute the number of elements in the d vector
n <- length(d)
# compute the mean of the d vector
dMean <- mean(d)
# compute the standard deviation of the d vector
dSD <- sd(d)
# compute the standard error of the mean for the d vector
dSEM <- dSD/sqrt(n)
# get tail proportions
lower_tail_proportion <- (100 - percentile)/(2*100)
upper_tail_proportion <- 1 - lower_tail_proportion
# compute the upper and lower cutoffs for the confidence
# interval of the mean
lower_cutoff <- dMean + qnorm(lower_tail_proportion)*dSEM
upper_cutoff <- dMean + qnorm(upper_tail_proportion)*dSEM
# return the values as a vector
return(c(lower_cutoff,upper_cutoff))
}
# run the function on the score variable contained in the
# normalSample data frame
normalSampleCI <- myConfInt(normalSample$score)
sampleAndComputeCI <- function(sampleSize=100){
mySample <- normalPopulation %>%
sample_n(sampleSize)
myCI <- myConfInt(mySample$score)
return(myCI)
}
nRuns <- 1000
results <- replicate(nRuns,sampleAndComputeCI())
resultsDf <- data.frame(t(results))
nRuns <- 1000
results <- replicate(nRuns,sampleAndComputeCI())
resultsDf <- data.frame(t(results))
names(resultsDf) <- c('lower_cutoff','upper_cutoff')
popSummary <- normalPopulation %>%
summarize(scoreMean = mean(score),
scoreSD = sd(score))
popSummary
View(popSummary)
library(tidyverse)
set.seed(12345)  # DO NOT CHANGE THIS
### FILL IN THE BLANK
### insert your sunet id in the blank - e.g. "russpold"
sunetID <- "______"
## PROVIDED CODE, DO NOT EDIT!
myMpg <- mpg
myMpg <- myMpg %>%
mutate(
Zhwy = (hwy - mean(hwy))/sd(hwy),
Zcty = (cty - mean(cty))/sd(cty)
)
# run this cell to show the example figure
#knitr::include_graphics("https://github.com/psych10/psych10/raw/master/problem_sets/Week9/scatterplot.png")
styler:::style_selection()
myMpg %>%
ggplot(aes(x = Zhwy, y = Zcty)) +
geom_point(aes(size = cyl), alpha = 0.2) +
xlim(-4.5, 4.5) +
ylim(-4.5, 4.5) +
labs(
x = "Highway mileage (Z-score)",
y = "City mileage (Z-score)"
)
ggsave('scatterplot.png')
mySubset <-
myMpg %>%
filter(class %in% c('suv','minivan'))
styler:::style_selection()
suvVsMinivan <- t.test(hwy ~ class, data = mySubset, alternative = "two.sided")
suvVsMinivan
hwySummary <-
mySubset %>%
group_by(class) %>%
summarize(
n = n(),
meanHwy = mean(hwy),
sdHwy = sd(hwy)
)
hwySummary
hwySummary
hwySummary$n[1]-1
hwySummary
# first compute the pooled standard deviation
hwySummary %>%
gather(key, variable, n:sdHwy)
# first compute the pooled standard deviation
hwySummary %>%
gather(key, variable, n:sdHwy) %>%
unite(class, key)
# first compute the pooled standard deviation
hwySummary %>%
gather(key, variable, n:sdHwy) %>%
unite(class, key, x)
?unite
# first compute the pooled standard deviation
hwySummary %>%
gather(key, variable, n:sdHwy) %>%
unite(class, key, new)
# first compute the pooled standard deviation
hwySummary %>%
gather(key, variable, n:sdHwy) %>%
unite(new, class, key)
# first compute the pooled standard deviation
hwySummary %>%
gather(key, variable, n:sdHwy) %>%
unite(new, class, key) %>%
spread(new, variable)
hwySummary$sdHwy[1]
hwySummary
s<-sqrt(((hwySummary$n[1]-1)*hwySummary$sdHwy[1]**2 + (hwySummary$n[2]-1)*hwySummary$sdHwy[2]**2)/(sum(hwySummary$n)-2))
s
# first compute the pooled standard deviation
hwySummary %>%
gather(key, variable, n:sdHwy) %>%
unite(new, class, key) %>%
spread(new, variable) %>%
mutate(
s = ((minivan_n - 1) * (minivan_sdHwy)^2 + (suv_n - 1) * (suv_sdHwy)^2) /
((minivan_n + suv_n) - 2)
) %>%
pull(s)
hwySummary$n[1]-1)
hwySummary$n[1]-1
hwySummary
hwySummary$sdHwy[1]**2
hwySummary$sdHwy[1]
hwySummary
2.06^2
hwySummary$n[2]-1
hwySummary
sum(hwySummary$n)-2
sum(hwySummary$n)-2
hwySummary %>%
gather(key, variable, n:sdHwy) %>%
unite(new, class, key) %>%
spread(new, variable)
hwySummary$sdHwy[2]*
hwySummary$sdHwy[2]
hwySummary %>%
gather(key, variable, n:sdHwy) %>%
unite(new, class, key) %>%
spread(new, variable)
hwySummary$sdHwy[2]
hwySummary %>%
gather(key, variable, n:sdHwy) %>%
unite(new, class, key) %>%
spread(new, variable)
# first compute the pooled standard deviation
hwySummary %>%
gather(key, variable, n:sdHwy) %>%
unite(new, class, key) %>%
spread(new, variable) %>%
mutate(
s = ((minivan_n - 1) * (minivan_sdHwy)^2 + (suv_n - 1) * (suv_sdHwy)^2) /
((minivan_n + suv_n) - 2)
) %>%
pull(s)
s<-sqrt(((hwySummary$n[1]-1)*hwySummary$sdHwy[1]**2 + (hwySummary$n[2]-1)*hwySummary$sdHwy[2]**2)/(sum(hwySummary$n)-2))
s
hwySummary
# first compute the pooled standard deviation
hwySummary %>%
gather(key, variable, n:sdHwy) %>%
unite(new, class, key) %>%
spread(new, variable) %>%
mutate(
s = (((minivan_n - 1) * (minivan_sdHwy)^2) + ((suv_n - 1) * (suv_sdHwy)^2)) /
((minivan_n + suv_n) - 2)
) %>%
pull(s)
# first compute the pooled standard deviation
hwySummary %>%
gather(key, variable, n:sdHwy) %>%
unite(new, class, key) %>%
spread(new, variable) %>%
mutate(
s = sqrt(((minivan_n - 1) * (minivan_sdHwy)^2 + (suv_n - 1) * (suv_sdHwy)^2) /
((minivan_n + suv_n) - 2))
) %>%
pull(s)
styler:::style_selection()
hwySummary$meanHwy[2]
hwySummary_spread <-
hwySummary %>%
gather(key, variable, n:sdHwy) %>%
unite(new, class, key) %>%
spread(new, variable)
hwySummary_spread
hwySummary_spread <-
hwySummary %>%
gather(key, variable, n:sdHwy) %>%
unite(new, class, key) %>%
spread(new, variable)
hwySummary_spread
styler:::style_selection()
hwySummary_spread <-
hwySummary_spread %>%
mutate(
s = sqrt(((minivan_n - 1) * (minivan_sdHwy)^2 + (suv_n - 1) * (suv_sdHwy)^2) /
((minivan_n + suv_n) - 2)),
diff = suv_meanHwy - suv_mean,
cohend = dHwy / s
)
hwySummary_spread <-
hwySummary_spread %>%
mutate(
s = sqrt(((minivan_n - 1) * (minivan_sdHwy)^2 + (suv_n - 1) * (suv_sdHwy)^2) /
((minivan_n + suv_n) - 2)),
diff = suv_meanHwy - suv_meanHwy,
cohend = diff / s
)
hwySummary_spread
hwySummary_spread <-
hwySummary_spread %>%
mutate(
s = sqrt(((minivan_n - 1) * (minivan_sdHwy)^2 + (suv_n - 1) * (suv_sdHwy)^2) /
((minivan_n + suv_n) - 2)),
diff = suv_meanHwy - minivan_meanHwy,
cohend = diff / s
)
hwySummary_spread
hwySummary$sdHwy[2]
effectSizeOfInterest <- 1/hwySummary_spread$suv_sdHwy
effectSizeOfInterest
effectSizeOfInterest <- 1/hwySummary$sdHwy[2]
effectSizeOfInterest
styler:::style_selection()
library(tidyverse)
source('https://raw.githubusercontent.com/psych10/psych10/master/problem_sets/Week5/week5_tests.R')
### FILL IN THE BLANK
### insert your sunet id in the blank - e.g. "russpold"
sunetID <- "norat"
### PROVIDED CODE
cat(paste('please confirm that your sunet ID is:',sunetID))
library(tidyverse)
source('https://raw.githubusercontent.com/psych10/psych10/master/problem_sets/Week5/week5_tests.R')
### FILL IN THE BLANK
### insert your sunet id in the blank - e.g. "russpold"
sunetID <- "norat"
### PROVIDED CODE
cat(paste('please confirm that your sunet ID is:',sunetID))
# create a list containing the data
d <- c(00,05,09,11,12,21,22,24,25,25,26,27,28,33,34,37)
### PROVIDED CODE
stem_test()
# recreate the stem and leaf plot using the appropriate R function
stem(d)
#### PROVIDED CODE
# this computes the sum of squared errors between two vectors
sum_squared_error <- function(v,d){
sse <- sum((d - v)^2)
return(sse)
}
# create a variable with all of the different possible values
# of the mean that we want to test. This should be a sequence of values,
# ranging from the smallest value of d to the largest value of d, in steps
# of .01.  you should find the smallest and largest values of d using
# the appropriate R functions; you should not type in the values directly.
d_with_steps <- seq(min(d), max(d), by = .01)
testvals <- d_with_steps
# use the sapply() function to apply the sum_squared_error() function
# for each value of testvals
ssevals <- sapply(testvals, sum_squared_error, d=d)
# now we need to find the test value that had the minimum value of ssevals
# use the R function that determines the location of the minimum of a vector
minsse_loc <- which.min(ssevals)
# now we find the value of the test statistic that minimized the sum of
# squared errors, using the location from the previous step
testval_with_minimum_sse <- minsse_loc
# print out the value minimizing the SSE along with the actual mean
# make sure that they are the same value!
print(testval_with_minimum_sse)
print(mean(d))
### PROVIDED CODE
cat(sprintf('SSE minimized at %0.2f\n',testval_with_minimum_sse))
cat(sprintf('actual mean = %0.2f\n',mean(d)))
# run this cell to show the example figure
knitr::include_graphics("https://github.com/psych10/psych10/raw/master/problem_sets/Week5/sseplot.png")
# first, we need to create a tibble that ggplot can use
# which contains the values that we computed above
# it should include a variable called testvals that contains the values from the
# testvals variable, and a variable called sse that contains the values from the
# ssevals variable
sseDf <- tibble(testval = testvals,
sse = ssevals)
# now plot the SSE as a function of the test value
# fill in the blanks to perform each of the individual operations
ggplot(sseDf, aes(x = testval, y = sse)) +
# add a line showing the relation between testval and sse
geom_line(color = 'black') +
# add a blue vertical line whose X intercept is the actual mean
geom_vline(xintercept = mean(d),
color = 'blue') +
# add a red horizontal line whose Y intercept is the minimum SSE value
geom_hline(yintercept = min(sseDf$sse),
color = 'red') +
# add a point with x position equal to the mean of d, and y position
# equal to the minimum SSE value
geom_point(aes(x = mean(d),y = min(sseDf$sse)))
## PROVIDED CODE
trackingdata <- read.csv('http://web.stanford.edu/group/poldracklab/myconnectome-data/base/behavior/trackingdata.txt',
sep='\t',
na.strings=c('.'))
scanData <-
trackingdata %>%
# select variables
select(day_of_week,panas.fatigue,panas.positive,panas.negative) %>%
# filter out values of day_of_week other than 2 or 4
filter(day_of_week == 2 | day_of_week == 4) %>%
# remove NA values
na.omit() %>%
# create new weekday variable. use the recode_factor() function
mutate(weekday = recode_factor(day_of_week, '2' = "Tues", '4' = 'Thurs')) %>%
# remove the day_of_week variable
select(-day_of_week)
scanDataSummary <- scanData %>%
group_by(weekday) %>%
summarise_all(funs(mean))
scanDataSummary
# run this cell to show the example figure
knitr::include_graphics("https://github.com/psych10/psych10/raw/master/problem_sets/Week5/fatigue_plot.png")
ggplot(scanData, aes(x = panas.fatigue, color = weekday)) +
geom_density()
# run this cell to show the example figure
knitr::include_graphics("https://github.com/psych10/psych10/raw/master/problem_sets/Week5/positive_plot.png")
ggplot(scanData, aes(x = panas.positive, color = weekday)) +
geom_density()
# run this cell to show the example figure
knitr::include_graphics("https://github.com/psych10/psych10/raw/master/problem_sets/Week5/scatter_plot.png")
ggplot(scanData, aes(x = panas.positive, y = panas.negative, color = weekday, size = panas.fatigue)) +
geom_point()
hours_spent <- 10
sunet_all <- read_csv(~/Desktop/all_psych10_sunet.csv)
sunet_all <- read_csv("~/Desktop/all_psych10_sunet.csv")
grades <- read_csv("~/Downloads/pset 6 grading - data_updated.csv")
graded <-
sunet_all %>%
left_join(grades, by = "sunet")
glimpse(sunet_all)
sunet_all <-
rename(sunet = sunet_all)
sunet_all <-
sunet_all %>%
rename(sunet = sunet_all)
graded <-
sunet_all %>%
left_join(grades, by = "sunet")
View(graded)
graded <-
graded %>%
mutate(final_score = if_else(is.na(final_score), 0, final_score)
)
write_csv(graded , "~/Desktop/week6/graded.csv")
write_csv(graded , "~/Desktop/week6_graded.csv")
library(tidyverse)
library(NHANES)
library(readr)
# change this to the location of the file you downloaded
hfi_file <- file.path('hfi_cc_2018.csv')
# change this to the location of the file you downloaded
hfi_file <- file.path('hfi_cc_2018.csv')
hfi <-
read.csv(hfi_file, stringsAsFactors = TRUE)
names(hfi) <- make.names(names(hfi), unique=TRUE)
str(hfi)
myvars <- c('year', 'countries', 'region', 'hf_score', 'ef_score')
newdata <- hfi[myvars]
print(newdata)
# run this cell to show the example figure
knitr::include_graphics("https://github.com/psych10/psych10/raw/master/problem_sets/Week6/plot2.png")
# create the data frame containing values for for 2016 only
hfi_2016 <-
newdata %>%
filter(year == 2016)
# make the scatter plot
hfi_2016 %>%
ggplot(aes(x = hf_score, y = ef_score)) +
geom_point() +
labs(title = "Relation between human economic freedom") +
xlab("Human Freedom Index") +
ylab("Economic Freedom Index")
hfi_2016 <-
hfi_2016 %>%
group_by(hf_score, ef_score) %>%
mutate(mean_score = mean(hf_score) , mean(ef_score)) %>%
ungroup(hf_score, ef_score)
hfi_2016 %>%
ggplot(aes(x = mean_score)) +
geom_density()
regionSummary <-
hfi %>%
group_by(region) %>%
summarise(mean_hf = mean(hf_score), mean_ef = mean(ef_score))
# print the summary, ordered by mean_hf in descending order
regionSummary %>%
arrange(desc(mean_hf, mean_ef))
## Oceania has the heighest economic freedom and the Middle East and North Africa has the lowest Human Freedom score.
hfi %>%
ggplot(aes(x = fct_reorder(region, hf_score, .desc = FALSE), y = hf_score)) + #look up the help page for fct_reorder to see how this works
geom_violin() + # specify the geometry
theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
labs(title ="Distributions of human freedom if different regions") +
xlab("Regions") +
ylab("Human Freedom Score")
hfi_limited %>%
ggplot(aes(x = year, y = hf_score, color = countries)) +
geom_point() +
geom_smooth() +
xlab("Year") +
ylab("Human Freedom Score")
library(tidyverse)
library(NHANES)
library(readr)
### FILL IN THE BLANK
### insert your sunet id in the blank - e.g. "russpold"
sunetID <- "dianajor"
### PROVIDED CODE
cat(paste('please confirm that your sunet ID is:',sunetID))
# change this to the location of the file you downloaded
hfi_file <- file.path('hfi_cc_2018.csv')
hfi <-
read.csv(hfi_file, stringsAsFactors = TRUE)
names(hfi) <- make.names(names(hfi), unique=TRUE)
str(hfi)
myvars <- c('year', 'countries', 'region', 'hf_score', 'ef_score')
newdata <- hfi[myvars]
print(newdata)
# run this cell to show the example figure
knitr::include_graphics("https://github.com/psych10/psych10/raw/master/problem_sets/Week6/plot2.png")
# create the data frame containing values for for 2016 only
hfi_2016 <-
newdata %>%
filter(year == 2016)
# make the scatter plot
hfi_2016 %>%
ggplot(aes(x = hf_score, y = ef_score)) +
geom_point() +
labs(title = "Relation between human economic freedom") +
xlab("Human Freedom Index") +
ylab("Economic Freedom Index")
hfi_2016 <-
hfi_2016 %>%
group_by(hf_score, ef_score) %>%
mutate(mean_score = mean(hf_score) , mean(ef_score)) %>%
ungroup(hf_score, ef_score)
# run this cell to show the example figure
knitr::include_graphics("https://github.com/psych10/psych10/raw/master/problem_sets/Week6/plot3.png")
hfi_2016 %>%
ggplot(aes(x = mean_score)) +
geom_density()
hfi_limited <-
hfi %>%
filter(countries == c("Singapore", "Thailand"))
# run this cell to show the example figure
knitr::include_graphics("https://github.com/psych10/psych10/raw/master/problem_sets/Week6/plot4.png")
hfi_limited %>%
ggplot(aes(x = year, y = hf_score, color = countries)) +
geom_point() +
geom_smooth() +
xlab("Year") +
ylab("Human Freedom Score")
